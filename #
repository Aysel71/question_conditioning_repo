# src/evaluation/attention_viz.py
"""
Comprehensive Visualization Suite –¥–ª—è Question-Conditioned Selector
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –∏–º–µ–Ω–Ω–æ –æ—Ç–æ–±—Ä–∞–ª–∞ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.gridspec import GridSpec
import seaborn as sns
from PIL import Image, ImageDraw, ImageFont
import torch
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional, Union
from pathlib import Path

# For creating attention overlays
import cv2


class AttentionVisualizer:
    """Visualizer –¥–ª—è attention maps –∏ selected patches"""
    
    def __init__(self, patch_size: int = 14, image_size: int = 336):
        self.patch_size = patch_size
        self.image_size = image_size
        self.patches_per_side = image_size // patch_size  # 24 for 336/14
        self.total_patches = self.patches_per_side ** 2  # 576
        
        # Color schemes
        self.colors = {
            'selected': '#FF6B6B',    # Red for selected
            'unselected': '#4ECDC4',  # Teal for unselected  
            'high_importance': '#FF4757',
            'medium_importance': '#FFA502',
            'low_importance': '#70A1FF',
            'background': '#F1F2F6'
        }
    
    def patch_coordinates_to_grid(self, patch_indices: torch.Tensor) -> np.ndarray:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç patch indices –≤ 2D grid coordinates"""
        patch_indices = patch_indices.cpu().numpy()
        grid = np.zeros((self.patches_per_side, self.patches_per_side))
        
        for idx in patch_indices:
            if idx < self.total_patches:
                row = idx // self.patches_per_side
                col = idx % self.patches_per_side
                grid[row, col] = 1
        
        return grid
    
    def importance_scores_to_grid(self, importance_scores: torch.Tensor) -> np.ndarray:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç importance scores –≤ 2D grid"""
        scores = importance_scores.cpu().numpy()
        if len(scores.shape) > 1:
            scores = scores.squeeze()
        
        # Reshape to 2D grid
        grid = scores[:self.total_patches].reshape(self.patches_per_side, self.patches_per_side)
        return grid
    
    def create_patch_overlay(
        self, 
        image: Union[Image.Image, np.ndarray], 
        selected_patches: torch.Tensor,
        importance_scores: torch.Tensor,
        alpha: float = 0.6
    ) -> Image.Image:
        """–°–æ–∑–¥–∞–µ—Ç overlay —Å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–º–∏ patches –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # Resize image to standard size
        image = image.resize((self.image_size, self.image_size))
        
        # Create overlay
        overlay = Image.new('RGBA', (self.image_size, self.image_size), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Get selected patches grid
        selected_grid = self.patch_coordinates_to_grid(selected_patches)
        importance_grid = self.importance_scores_to_grid(importance_scores)
        
        # Draw patches
        for i in range(self.patches_per_side):
            for j in range(self.patches_per_side):
                x1 = j * self.patch_size
                y1 = i * self.patch_size
                x2 = x1 + self.patch_size
                y2 = y1 + self.patch_size
                
                is_selected = selected_grid[i, j] > 0
                importance = importance_grid[i, j]
                
                if is_selected:
                    # Color intensity based on importance
                    if importance > 0.8:
                        color = self.colors['high_importance']
                    elif importance > 0.5:
                        color = self.colors['medium_importance']
                    else:
                        color = self.colors['low_importance']
                    
                    # Convert hex to RGB and add alpha
                    color_rgb = tuple(int(color[i:i+2], 16) for i in (1, 3, 5))
                    color_rgba = color_rgb + (int(255 * alpha),)
                    
                    draw.rectangle([x1, y1, x2, y2], fill=color_rgba, outline=(255, 255, 255, 200), width=1)
        
        # Combine with original image
        result = Image.alpha_composite(image.convert('RGBA'), overlay)
        return result.convert('RGB')
    
    def visualize_question_comparison(
        self,
        image: Image.Image,
        questions_and_outputs: List[Tuple[str, Dict]],
        save_path: Optional[str] = None,
        figsize: Tuple[int, int] = (20, 12)
    ) -> plt.Figure:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç attention patterns –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        
        Args:
            image: Original image
            questions_and_outputs: List of (question, model_outputs) tuples
            save_path: Path to save figure
            figsize: Figure size
        """
        
        num_questions = len(questions_and_outputs)
        fig = plt.figure(figsize=figsize)
        gs = GridSpec(3, num_questions + 1, figure=fig, hspace=0.3, wspace=0.2)
        
        # Original image
        ax_orig = fig.add_subplot(gs[0, 0])
        ax_orig.imshow(image)
        ax_orig.set_title('Original Image', fontsize=14, fontweight='bold')
        ax_orig.axis('off')
        
        # For each question
        for idx, (question, outputs) in enumerate(questions_and_outputs):
            col = idx + 1
            
            # Selected patches overlay
            ax_overlay = fig.add_subplot(gs[0, col])
            overlay_img = self.create_patch_overlay(
                image, 
                outputs['selected_indices'][0], 
                outputs['importance_scores'][0]
            )
            ax_overlay.imshow(overlay_img)
            ax_overlay.set_title(f'Q: {question[:30]}...', fontsize=10, fontweight='bold')
            ax_overlay.axis('off')
            
            # Importance heatmap
            ax_heat = fig.add_subplot(gs[1, col])
            importance_grid = self.importance_scores_to_grid(outputs['importance_scores'][0])
            im = ax_heat.imshow(importance_grid, cmap='hot', interpolation='nearest')
            ax_heat.set_title('Importance Scores', fontsize=10)
            ax_heat.axis('off')
            plt.colorbar(im, ax=ax_heat, fraction=0.046, pad=0.04)
            
            # Selection mask
            ax_mask = fig.add_subplot(gs[2, col])
            selected_grid = self.patch_coordinates_to_grid(outputs['selected_indices'][0])
            ax_mask.imshow(selected_grid, cmap='Reds', interpolation='nearest')
            ax_mask.set_title('Selected Patches', fontsize=10)
            ax_mask.axis('off')
            
            # Add statistics text
            sparsity = outputs['selection_mask'][0].float().mean().item()
            max_importance = outputs['importance_scores'][0].max().item()
            
            stats_text = f"Sparsity: {sparsity:.2%}\nMax Importance: {max_importance:.3f}"
            ax_mask.text(0.02, 0.98, stats_text, transform=ax_mask.transAxes, 
                        verticalalignment='top', fontsize=8,
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        plt.suptitle('Question-Conditioned Visual Attention Comparison', 
                    fontsize=16, fontweight='bold', y=0.95)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"üíæ Visualization saved to: {save_path}")
        
        return fig
    
    def create_attention_evolution_gif(
        self,
        image: Image.Image,
        question: str,
        importance_scores_sequence: List[torch.Tensor],
        save_path: str,
        duration: int = 500
    ):
        """
        –°–æ–∑–¥–∞–µ—Ç GIF –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∏–π —ç–≤–æ–ª—é—Ü–∏—é attention –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            image: Original image
            question: Question text
            importance_scores_sequence: List of importance scores from different epochs
            save_path: Path to save GIF
            duration: Duration per frame in milliseconds
        """
        
        frames = []
        
        for epoch, importance_scores in enumerate(importance_scores_sequence):
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            
            # Patch overlay
            # Mock selected patches based on top importance scores
            top_k = int(len(importance_scores) * 0.4)  # 40% sparsity
            _, selected_indices = torch.topk(importance_scores.squeeze(), top_k)
            
            overlay_img = self.create_patch_overlay(image, selected_indices, importance_scores)
            ax1.imshow(overlay_img)
            ax1.set_title(f'Epoch {epoch + 1}: {question}', fontweight='bold')
            ax1.axis('off')
            
            # Importance heatmap
            importance_grid = self.importance_scores_to_grid(importance_scores)
            im = ax2.imshow(importance_grid, cmap='hot', interpolation='nearest')
            ax2.set_title('Importance Scores', fontweight='bold')
            ax2.axis('off')
            plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)
            
            plt.tight_layout()
            
            # Convert to image
            fig.canvas.draw()
            frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
            frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))
            frames.append(Image.fromarray(frame))
            
            plt.close(fig)
        
        # Save as GIF
        frames[0].save(
            save_path, 
            save_all=True, 
            append_images=frames[1:], 
            duration=duration, 
            loop=0
        )
        print(f"üé¨ Attention evolution GIF saved to: {save_path}")
    
    def create_sparsity_analysis_plot(
        self,
        questions: List[str],
        sparsity_ratios: List[float],
        importance_distributions: List[np.ndarray],
        save_path: Optional[str] = None
    ) -> plt.Figure:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç sparsity patterns –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤
        """
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. Sparsity by question type
        question_types = []
        for q in questions:
            if 'color' in q.lower():
                question_types.append('Color')
            elif 'how many' in q.lower():
                question_types.append('Count')
            elif 'where' in q.lower():
                question_types.append('Location')
            else:
                question_types.append('General')
        
        ax1 = axes[0, 0]
        sns.boxplot(x=question_types, y=sparsity_ratios, ax=ax1)
        ax1.set_title('Sparsity by Question Type', fontweight='bold')
        ax1.set_ylabel('Sparsity Ratio')
        ax1.axhline(y=0.4, color='red', linestyle='--', alpha=0.7, label='Target (40%)')
        ax1.legend()
        
        # 2. Importance score distributions
        ax2 = axes[0, 1]
        for i, (q, dist) in enumerate(zip(questions[:4], importance_distributions[:4])):
            ax2.hist(dist, alpha=0.6, bins=30, label=f'Q{i+1}: {q[:20]}...')
        ax2.set_title('Importance Score Distributions', fontweight='bold')
        ax2.set_xlabel('Importance Score')
        ax2.set_ylabel('Frequency')
        ax2.legend(fontsize=8)
        
        # 3. Sparsity vs Question Length
        ax3 = axes[1, 0]
        question_lengths = [len(q.split()) for q in questions]
        ax3.scatter(question_lengths, sparsity_ratios, alpha=0.7)
        ax3.set_title('Sparsity vs Question Length', fontweight='bold')
        ax3.set_xlabel('Question Length (words)')
        ax3.set_ylabel('Sparsity Ratio')
        
        # Add trend line
        z = np.polyfit(question_lengths, sparsity_ratios, 1)
        p = np.poly1d(z)
        ax3.plot(question_lengths, p(question_lengths), "r--", alpha=0.8)
        
        # 4. Attention concentration heatmap
        ax4 = axes[1, 1]
        if importance_distributions:
            # Calculate attention concentration for each question
            concentrations = []
            for dist in importance_distributions:
                # Entropy as measure of concentration
                dist_norm = dist / dist.sum()
                entropy = -np.sum(dist_norm * np.log(dist_norm + 1e-8))
                concentration = 1 / (entropy + 1e-8)  # Higher = more concentrated
                concentrations.append(concentration)
            
            # Create heatmap of concentrations
            conc_grid = np.array(concentrations[:16]).reshape(4, 4) if len(concentrations) >= 16 else np.array([[0]])
            im = ax4.imshow(conc_grid, cmap='viridis', aspect='auto')
            ax4.set_title('Attention Concentration Map', fontweight='bold')
            plt.colorbar(im, ax=ax4, fraction=0.046, pad=0.04)
        
        plt.suptitle('Sparsity Analysis Across Question Types', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"üìä Sparsity analysis saved to: {save_path}")
        
        return fig
    
    def create_interpretability_dashboard(
        self,
        image: Image.Image,
        question: str,
        model_outputs: Dict,
        save_path: Optional[str] = None
    ) -> plt.Figure:
        """
        –°–æ–∑–¥–∞–µ—Ç comprehensive dashboard –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
        """
        
        fig = plt.figure(figsize=(20, 12))
        gs = GridSpec(3, 4, figure=fig, hspace=0.3, wspace=0.3)
        
        # 1. Original image
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.imshow(image)
        ax1.set_title('Original Image', fontsize=14, fontweight='bold')
        ax1.axis('off')
        
        # 2. Selected patches overlay
        ax2 = fig.add_subplot(gs[0, 1])
        overlay_img = self.create_patch_overlay(
            image, 
            model_outputs['selected_indices'][0], 
            model_outputs['importance_scores'][0]
        )
        ax2.imshow(overlay_img)
        ax2.set_title('Selected Patches', fontsize=14, fontweight='bold')
        ax2.axis('off')
        
        # 3. Importance heatmap
        ax3 = fig.add_subplot(gs[0, 2])
        importance_grid = self.importance_scores_to_grid(model_outputs['importance_scores'][0])
        im1 = ax3.imshow(importance_grid, cmap='hot', interpolation='nearest')
        ax3.set_title('Importance Scores', fontsize=14, fontweight='bold')
        ax3.axis('off')
        plt.colorbar(im1, ax=ax3, fraction=0.046, pad=0.04)
        
        # 4. Selection mask binary
        ax4 = fig.add_subplot(gs[0, 3])
        selected_grid = self.patch_coordinates_to_grid(model_outputs['selected_indices'][0])
        ax4.imshow(selected_grid, cmap='Reds', interpolation='nearest')
        ax4.set_title('Binary Selection', fontsize=14, fontweight='bold')
        ax4.axis('off')
        
        # 5. Cross-attention weights (if available)
        if 'attention_weights' in model_outputs:
            ax5 = fig.add_subplot(gs[1, :2])
            attn_weights = model_outputs['attention_weights'][0].cpu().numpy()  # [576, seq_len]
            im2 = ax5.imshow(attn_weights, cmap='Blues', aspect='auto')
            ax5.set_title('Cross-Attention: Visual Patches ‚Üí Question Tokens', fontsize=14, fontweight='bold')
            ax5.set_xlabel('Question Tokens')
            ax5.set_ylabel('Visual Patches')
            plt.colorbar(im2, ax=ax5, fraction=0.046, pad=0.04)
        
        # 6. Statistics and metrics
        ax6 = fig.add_subplot(gs[1, 2:])
        ax6.axis('off')
        
        # Calculate statistics
        sparsity = model_outputs['selection_mask'][0].float().mean().item()
        max_importance = model_outputs['importance_scores'][0].max().item()
        min_importance = model_outputs['importance_scores'][0].min().item()
        mean_importance = model_outputs['importance_scores'][0].mean().item()
        
        selected_patches_count = model_outputs['selected_indices'][0].shape[0]
        total_patches = model_outputs['importance_scores'][0].shape[0]
        
        stats_text = f"""
        üìä SELECTION STATISTICS:
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        
        üéØ Question: "{question}"
        
        üìà Sparsity Metrics:
        ‚Ä¢ Selected Patches: {selected_patches_count}/{total_patches} ({sparsity:.1%})
        ‚Ä¢ Target Sparsity: 40%
        ‚Ä¢ Efficiency Gain: {1/sparsity:.1f}x fewer tokens
        
        üíé Importance Scores:
        ‚Ä¢ Maximum: {max_importance:.4f}
        ‚Ä¢ Minimum: {min_importance:.4f}  
        ‚Ä¢ Average: {mean_importance:.4f}
        ‚Ä¢ Range: {max_importance - min_importance:.4f}
        
        üöÄ Performance Impact:
        ‚Ä¢ Visual Tokens: {total_patches} ‚Üí {selected_patches_count}
        ‚Ä¢ Memory Reduction: {(1-sparsity)*100:.1f}%
        ‚Ä¢ Estimated Speedup: {1/sparsity:.1f}x
        """
        
        ax6.text(0.05, 0.95, stats_text, transform=ax6.transAxes, 
                verticalalignment='top', fontsize=12, fontfamily='monospace',
                bbox=dict(boxstyle='round,pad=1', facecolor='lightgray', alpha=0.8))
        
        # 7. Importance score distribution
        ax7 = fig.add_subplot(gs[2, :2])
        importance_scores = model_outputs['importance_scores'][0].cpu().numpy().flatten()
        ax7.hist(importance_scores, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        ax7.axvline(x=mean_importance, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_importance:.3f}')
        
        # Mark selection threshold
        sorted_scores = np.sort(importance_scores)[::-1]
        threshold_idx = int(len(sorted_scores) * sparsity)
        threshold = sorted_scores[threshold_idx] if threshold_idx < len(sorted_scores) else sorted_scores[-1]
        ax7.axvline(x=threshold, color='green', linestyle='--', linewidth=2, label=f'Selection Threshold: {threshold:.3f}')
        
        ax7.set_title('Importance Score Distribution', fontsize=14, fontweight='bold')
        ax7.set_xlabel('Importance Score')
        ax7.set_ylabel('Frequency')
        ax7.legend()
        ax7.grid(True, alpha=0.3)
        
        # 8. Top selected patches preview
        ax8 = fig.add_subplot(gs[2, 2:])
        ax8.axis('off')
        
        # Show top 5 selected patches
        top_scores, top_indices = torch.topk(model_outputs['importance_scores'][0].squeeze(), 5)
        
        patches_text = "üî• TOP SELECTED PATCHES:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        for i, (score, idx) in enumerate(zip(top_scores, top_indices)):
            row = idx.item() // self.patches_per_side
            col = idx.item() % self.patches_per_side
            patches_text += f"{i+1}. Patch #{idx.item():3d} (row {row:2d}, col {col:2d}) - Score: {score.item():.4f}\n"
        
        patches_text += f"\nüí° These patches contain the most relevant visual information for answering: '{question}'"
        
        ax8.text(0.05, 0.95, patches_text, transform=ax8.transAxes,
                verticalalignment='top', fontsize=11, fontfamily='monospace',
                bbox=dict(boxstyle='round,pad=1', facecolor='lightyellow', alpha=0.8))
        
        plt.suptitle(f'üîç Interpretability Dashboard: Question-Conditioned Selection', 
                    fontsize=18, fontweight='bold', y=0.98)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"üìã Dashboard saved to: {save_path}")
        
        return fig


def demo_visualization():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è visualization capabilities"""
    
    print("üé® Question-Conditioned Selector Visualization Demo")
    print("=" * 60)
    
    # Create visualizer
    visualizer = AttentionVisualizer()
    
    # Mock data for demonstration
    mock_image = Image.new('RGB', (336, 336), color='lightblue')
    
    questions = [
        "What color is the car?",
        "How many people are there?", 
        "Where is the dog?",
        "What is the person doing?"
    ]
    
    # Mock model outputs
    mock_outputs = []
    for i, question in enumerate(questions):
        # Create different attention patterns for different questions
        if 'color' in question:
            importance_scores = torch.cat([
                torch.ones(200) * 0.8,  # High importance in center
                torch.ones(376) * 0.2   # Low importance elsewhere
            ])
        elif 'how many' in question:
            importance_scores = torch.rand(576) * 0.6 + 0.3  # Distributed attention
        elif 'where' in question:
            importance_scores = torch.cat([
                torch.ones(100) * 0.7,   # Edges
                torch.ones(376) * 0.1,   # Center  
                torch.ones(100) * 0.7    # Edges
            ])
        else:
            importance_scores = torch.rand(576) * 0.5 + 0.2
        
        # Add some noise
        importance_scores += torch.randn(576) * 0.1
        importance_scores = torch.clamp(importance_scores, 0, 1)
        
        # Top-k selection
        k = int(576 * 0.4)  # 40% sparsity
        _, selected_indices = torch.topk(importance_scores, k)
        
        # Create selection mask
        selection_mask = torch.zeros(576)
        selection_mask[selected_indices] = 1
        
        mock_outputs.append({
            'importance_scores': importance_scores.unsqueeze(0),
            'selected_indices': selected_indices.unsqueeze(0),
            'selection_mask': selection_mask.unsqueeze(0),
            'attention_weights': torch.rand(1, 576, 10)  # Mock cross-attention
        })
    
    # Create output directory
    output_dir = Path("demo_visualizations")
    output_dir.mkdir(exist_ok=True)
    
    print("üîç Creating question comparison visualization...")
    questions_and_outputs = list(zip(questions, mock_outputs))
    fig1 = visualizer.visualize_question_comparison(
        mock_image, 
        questions_and_outputs,
        save_path=output_dir / "question_comparison.png"
    )
    plt.close(fig1)
    
    print("üìä Creating sparsity analysis...")
    sparsity_ratios = [out['selection_mask'][0].float().mean().item() for out in mock_outputs]
    importance_distributions = [out['importance_scores'][0].cpu().numpy() for out in mock_outputs]
    
    fig2 = visualizer.create_sparsity_analysis_plot(
        questions,
        sparsity_ratios, 
        importance_distributions,
        save_path=output_dir / "sparsity_analysis.png"
    )
    plt.close(fig2)
    
    print("üìã Creating interpretability dashboard...")
    fig3 = visualizer.create_interpretability_dashboard(
        mock_image,
        questions[0],
        mock_outputs[0],
        save_path=output_dir / "interpretability_dashboard.png"
    )
    plt.close(fig3)
    
    print("üé¨ Creating attention evolution GIF...")
    # Mock evolution over epochs
    evolution_sequence = []
    base_scores = mock_outputs[0]['importance_scores'][0]
    for epoch in range(5):
        # Simulate learning: gradually more focused attention
        noise_level = 0.5 * (1 - epoch / 4)  # Decreasing noise
        evolved_scores = base_scores + torch.randn_like(base_scores) * noise_level
        evolved_scores = torch.clamp(evolved_scores, 0, 1)
        evolution_sequence.append(evolved_scores)
    
    visualizer.create_attention_evolution_gif(
        mock_image,
        questions[0],
        evolution_sequence,
        save_path=str(output_dir / "attention_evolution.gif")
    )
    
    print(f"\n‚úÖ Demo visualizations created in: {output_dir}")
    print("\nüìÅ Generated files:")
    for file in output_dir.glob("*"):
        print(f"  üìÑ {file.name}")
    
    print(f"\nüéØ Key visualization features:")
    print(f"  üî¥ Selected patches overlay on original image")
    print(f"  üå°Ô∏è  Importance score heatmaps")
    print(f"  üìä Question type comparison")
    print(f"  üìà Sparsity analysis across question types")
    print(f"  üìã Comprehensive interpretability dashboard")
    print(f"  üé¨ Attention evolution during training")
    
    return output_dir


if __name__ == "__main__":
    demo_visualization()
